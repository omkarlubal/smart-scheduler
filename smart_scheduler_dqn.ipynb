{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:00:01.245361Z",
     "start_time": "2024-03-25T02:59:51.891128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omkarlubal/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"GPUs Available: \", tf.config.experimental.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:00:01.808110Z",
     "start_time": "2024-03-25T03:00:01.804564Z"
    }
   },
   "id": "ffc27a779aae6cd9",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, env, state_size, action_size, batch_size):\n",
    "        self.env = env\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay_rate = 0.001\n",
    "        self.learning_rate = 0.01\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.target_model.set_weights(self.model.get_weights()) \n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, actions_available, reward, next_state, done):\n",
    "        self.memory.append((state, action, actions_available, reward, next_state, done))\n",
    "    \n",
    "    def one_hot_state(self, state):\n",
    "        return np.reshape(state, [1, self.state_size])\n",
    "    \n",
    "    def masked_predict(self, model, state, actions_available):\n",
    "        act_values = model.predict(state, verbose=0)\n",
    "        # mask other actions as they are not available to assign to vm\n",
    "        for actions in actions_available:\n",
    "            act_values[0][actions] = 0\n",
    "        return act_values\n",
    "\n",
    "    def act(self, state, actions_available):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return self.env.sample()\n",
    "        act_values = self.masked_predict(self.model, state, actions_available)\n",
    "        return np.argmax(act_values)\n",
    "\n",
    "    def replay(self, episode):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        \n",
    "        # Initialize arrays for inputs and targets\n",
    "        states = np.zeros((self.batch_size, self.state_size))\n",
    "        targets = np.zeros((self.batch_size, self.action_size))\n",
    "        \n",
    "        for i, (state, action, actions_available, reward, next_state, done) in enumerate(minibatch):\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma * np.amax(self.masked_predict(self.target_model, next_state, actions_available)[0]))\n",
    "            target_f = self.masked_predict(self.model, state, actions_available)\n",
    "            # update reward for a given action\n",
    "            target_f[0][action] = target\n",
    "            \n",
    "            # Store the states and the targets\n",
    "            states[i] = state\n",
    "            targets[i] = target_f\n",
    "            \n",
    "        self.model.fit(states, targets, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon = self.epsilon_min + \\\n",
    "    (1 - self.epsilon_min) * np.exp(-self.epsilon_decay_rate) # added 8874 as the first training episode ended on 8874\n",
    "\n",
    "    def target_train(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def get_epsilon(self):\n",
    "        return self.epsilon\n",
    "        \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:01:34.668084Z",
     "start_time": "2024-03-25T03:01:34.654330Z"
    }
   },
   "id": "d9d4696ed11fe2d3",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TaskWorkflow:\n",
    "    def __init__(self, adj_matrix, vms):\n",
    "        self.adj_matrix = adj_matrix\n",
    "        self.vms = vms\n",
    "        self.vm_status = np.zeros(len(vms))\n",
    "        self.max_vm = max(vms)\n",
    "\n",
    "    def reset(self):\n",
    "        for key in self.adj_matrix:\n",
    "            self.adj_matrix[key][\"finished\"] = False\n",
    "        \n",
    "        vm_status = [0] * len(self.vms)\n",
    "        return vm_status\n",
    "\n",
    "    def step(self, action):\n",
    "        # Take an action in the environment and return the next state, reward, and whether the episode is done\n",
    "        # action -> assign a task in the vm\n",
    "        \n",
    "        next_state = self.vm_status\n",
    "        # base reward is max_vm used when terminal state\n",
    "        reward = self.max_vm\n",
    "        \n",
    "        # get any next available task\n",
    "        task_to_assign = self.get_next_available_tasks()\n",
    "        if len(task_to_assign) > 0:\n",
    "            \"\"\"\n",
    "            Strategy - one task at a step\n",
    "            1. Check if vm is free, then assign else free vm and then assign, first come random serve\n",
    "            \"\"\"\n",
    "            \n",
    "            self.adj_matrix[random.choice(list(task_to_assign))][\"finished\"] = True\n",
    "            # get any next available vm \n",
    "            free_vms = [idx for idx in range(0, len(self.vm_status)) if self.vm_status[idx]==0]\n",
    "            if len(free_vms) == 0:\n",
    "                # no vm is free, so select the next fastest available VM\n",
    "                vm_num = np.argmin(self.vm_status)\n",
    "                # also update remaining execution time for all other vms\n",
    "                # subtracting the selected min execution time\n",
    "                self.vm_status = np.maximum(self.vm_status - np.min(self.vm_status), 0)\n",
    "            else:\n",
    "                vm_num = random.choice(free_vms)\n",
    "            \n",
    "            selected_vm_capacity = self.vms[vm_num]\n",
    "            # update state: amount of time required to process it\n",
    "            self.vm_status[vm_num] = self.adj_matrix[action][\"load\"] / selected_vm_capacity\n",
    "            \n",
    "            # get reward from action\n",
    "            # high computing power -> low reward\n",
    "            reward = self.max_vm - selected_vm_capacity\n",
    "            next_state = self.vm_status\n",
    "            done = False\n",
    "            \n",
    "        else:\n",
    "            done = True\n",
    "        return next_state, reward, done\n",
    "        \n",
    "    def get_action_space_size(self):\n",
    "        return len(self.adj_matrix)\n",
    "    \n",
    "    def get_state_space_size(self):\n",
    "        return len(self.vms)\n",
    "    \n",
    "    def get_next_available_tasks(self):\n",
    "        # return a random task id\n",
    "        unfinished_tasks = set()\n",
    "    \n",
    "        # Start BFS from the root tasks (tasks with no dependencies)\n",
    "        queue = deque([task_number for task_number, task_data in self.adj_matrix.items() if task_data[\"depends\"] == -1])\n",
    "        # Perform BFS, assuming no cyclic dependency\n",
    "        while queue:\n",
    "            current_parent = queue.popleft()\n",
    "            if not self.adj_matrix[current_parent][\"finished\"]:\n",
    "                unfinished_tasks.add(current_parent)\n",
    "    \n",
    "            # Add next unfinished children tasks to the queue\n",
    "            for curr_task_number, curr_task_data in self.adj_matrix.items():\n",
    "                # check if child has parent dep, child task is unfinished, parent task is finished\n",
    "                if curr_task_data[\"depends\"] == int(current_parent): \n",
    "                    if curr_task_data[\"finished\"]:\n",
    "                        queue.append(curr_task_number)\n",
    "                    else:\n",
    "                        if self.adj_matrix[current_parent][\"finished\"]:\n",
    "                            unfinished_tasks.add(curr_task_number)\n",
    "        return unfinished_tasks\n",
    "    \n",
    "    def sample(self):\n",
    "        unfinished_tasks = self.get_next_available_tasks()\n",
    "        return -1 if len(unfinished_tasks) == 0 else random.choice(list(unfinished_tasks))\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:01:35.282739Z",
     "start_time": "2024-03-25T03:01:35.274783Z"
    }
   },
   "id": "17ac9840fcd292cf",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing weights...\n",
      "2024-03-25 03:01:35.964235 : Episode 0 total reward:150 avg reward: 0.3 epsilon: 1 time elapsed: 0.00min\n",
      "2024-03-25 03:01:35.974202 : Episode 1 total reward:170 avg reward: 0.34 epsilon: 1 time elapsed: 0.00min\n",
      "2024-03-25 03:01:35.984630 : Episode 2 total reward:130 avg reward: 0.26 epsilon: 1 time elapsed: 0.00min\n",
      "2024-03-25 03:01:35.994659 : Episode 3 total reward:150 avg reward: 0.3 epsilon: 1 time elapsed: 0.00min\n",
      "2024-03-25 03:01:36.004747 : Episode 4 total reward:170 avg reward: 0.34 epsilon: 1 time elapsed: 0.00min\n",
      "2024-03-25 03:01:36.014962 : Episode 5 total reward:90 avg reward: 0.18 epsilon: 1 time elapsed: 0.00min\n",
      "2024-03-25 03:01:36.024944 : Episode 6 total reward:70 avg reward: 0.14 epsilon: 1 time elapsed: 0.00min\n",
      "2024-03-25 03:01:55.938645 : Episode 7 total reward:170 avg reward: 0.34 epsilon: 0.9990104948350412 time elapsed: 0.33min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 37\u001B[0m\n\u001B[1;32m     35\u001B[0m next_state \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mone_hot_state(next_state)\n\u001B[1;32m     36\u001B[0m agent\u001B[38;5;241m.\u001B[39mremember(state, action, actions_available, reward, next_state, done)\n\u001B[0;32m---> 37\u001B[0m \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplay\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepisode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     39\u001B[0m state \u001B[38;5;241m=\u001B[39m next_state\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m done:\n",
      "Cell \u001B[0;32mIn[7], line 61\u001B[0m, in \u001B[0;36mDQNAgent.replay\u001B[0;34m(self, episode)\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n\u001B[1;32m     60\u001B[0m     target \u001B[38;5;241m=\u001B[39m (reward \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgamma \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mamax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmasked_predict(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_model, next_state, actions_available)[\u001B[38;5;241m0\u001B[39m]))\n\u001B[0;32m---> 61\u001B[0m target_f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmasked_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactions_available\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;66;03m# update reward for a given action\u001B[39;00m\n\u001B[1;32m     63\u001B[0m target_f[\u001B[38;5;241m0\u001B[39m][action] \u001B[38;5;241m=\u001B[39m target\n",
      "Cell \u001B[0;32mIn[7], line 36\u001B[0m, in \u001B[0;36mDQNAgent.masked_predict\u001B[0;34m(self, model, state, actions_available)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmasked_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m, model, state, actions_available):\n\u001B[0;32m---> 36\u001B[0m     act_values \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;66;03m# mask other actions as they are not available to assign to vm\u001B[39;00m\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m actions \u001B[38;5;129;01min\u001B[39;00m actions_available:\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/keras/src/engine/training.py:2620\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   2611\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m   2612\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   2613\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   2614\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2617\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m   2618\u001B[0m         )\n\u001B[0;32m-> 2620\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2621\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2622\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2623\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2624\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2625\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2626\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2627\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2628\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2629\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2630\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2631\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2633\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[1;32m   2634\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1688\u001B[0m, in \u001B[0;36mget_data_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1686\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1687\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1688\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataHandler\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:1292\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001B[0m\n\u001B[1;32m   1289\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[1;32m   1291\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[0;32m-> 1292\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1294\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1296\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1298\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1299\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1300\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1301\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1302\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1303\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1305\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpss_evaluation_shards\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpss_evaluation_shards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1308\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[1;32m   1310\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:355\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[1;32m    351\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m flat_dataset\n\u001B[1;32m    353\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m indices_dataset\u001B[38;5;241m.\u001B[39mflat_map(slice_batch_indices)\n\u001B[0;32m--> 355\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mslice_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    359\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshuffle_batch\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch):\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/keras/src/engine/data_adapter.py:387\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.slice_inputs\u001B[0;34m(self, indices_dataset, inputs)\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mslice_inputs\u001B[39m(\u001B[38;5;28mself\u001B[39m, indices_dataset, inputs):\n\u001B[1;32m    373\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Slice inputs into a Dataset of batches.\u001B[39;00m\n\u001B[1;32m    374\u001B[0m \n\u001B[1;32m    375\u001B[0m \u001B[38;5;124;03m    Given a Dataset of batch indices and the unsliced inputs,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;124;03m      A Dataset of input batches matching the batch indices.\u001B[39;00m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 387\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzip\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_tensors\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrepeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrab_batch\u001B[39m(i, data):\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mnest\u001B[38;5;241m.\u001B[39mmap_structure(\n\u001B[1;32m    393\u001B[0m             \u001B[38;5;28;01mlambda\u001B[39;00m d: tf\u001B[38;5;241m.\u001B[39mgather(d, i, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), data\n\u001B[1;32m    394\u001B[0m         )\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:1078\u001B[0m, in \u001B[0;36mDatasetV2.zip\u001B[0;34m(datasets, name, *args)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1077\u001B[0m   datasets \u001B[38;5;241m=\u001B[39m args\n\u001B[0;32m-> 1078\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mzip_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_zip\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/zip_op.py:24\u001B[0m, in \u001B[0;36m_zip\u001B[0;34m(datasets, name)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_zip\u001B[39m(datasets, name):  \u001B[38;5;66;03m# pylint: disable=redefined-builtin\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ZipDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdatasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/tensorflow/python/data/ops/zip_op.py:51\u001B[0m, in \u001B[0;36m_ZipDataset.__init__\u001B[0;34m(self, datasets, name)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_structure \u001B[38;5;241m=\u001B[39m nest\u001B[38;5;241m.\u001B[39mpack_sequence_as(\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_datasets, [ds\u001B[38;5;241m.\u001B[39melement_spec \u001B[38;5;28;01mfor\u001B[39;00m ds \u001B[38;5;129;01min\u001B[39;00m nest\u001B[38;5;241m.\u001B[39mflatten(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_datasets)]\n\u001B[1;32m     49\u001B[0m )\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name \u001B[38;5;241m=\u001B[39m name\n\u001B[0;32m---> 51\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzip_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variant_tensor\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mds\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_datasets\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_common_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(variant_tensor)\n",
      "File \u001B[0;32m~/alpha/PycharmProjects/shodai/.venv3.9/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:8234\u001B[0m, in \u001B[0;36mzip_dataset\u001B[0;34m(input_datasets, output_types, output_shapes, metadata, name)\u001B[0m\n\u001B[1;32m   8232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[1;32m   8233\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 8234\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   8235\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mZipDataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_datasets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_types\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   8236\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_shapes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   8237\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[1;32m   8238\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "adj_matrix = {\n",
    "    0: {\"load\": 400, \"depends\": -1, \"finished\": True},\n",
    "    1: {\"load\": 300, \"depends\": 0, \"finished\": True},\n",
    "    2: {\"load\": 600, \"depends\": 0, \"finished\": False},\n",
    "    3: {\"load\": 200, \"depends\": 0, \"finished\": False},\n",
    "    4: {\"load\": 120, \"depends\": 1, \"finished\": False},\n",
    "    5: {\"load\": 100, \"depends\": 2, \"finished\": False},\n",
    "    6: {\"load\": 350, \"depends\": 3, \"finished\": False},\n",
    "    7: {\"load\": 800, \"depends\": 0, \"finished\": False},\n",
    "}\n",
    "\n",
    "vms = [50, 30, 10]\n",
    "\n",
    "env = TaskWorkflow(adj_matrix, vms)\n",
    "\n",
    "agent = DQNAgent(state_size=env.get_state_space_size(), action_size=env.get_action_space_size(), batch_size=64, env=env)\n",
    "\n",
    "# Training the DQN agent\n",
    "num_episodes = 10000\n",
    "total_start = time.time()\n",
    "weights_file_name = \"weights.h5\"\n",
    "if os.path.exists(weights_file_name):\n",
    "    agent.load(weights_file_name)\n",
    "    print(\"Loaded existing weights...\")\n",
    "for episode in range(num_episodes):\n",
    "    state = agent.one_hot_state(env.reset())\n",
    "    reward_per_ep = 0\n",
    "    for time_step in range(100):  # Adjust the maximum time steps as needed\n",
    "        actions_available = env.get_next_available_tasks()\n",
    "        action = agent.act(state, actions_available)\n",
    "        next_state, reward, done, = env.step(action)\n",
    "        # print(next_state, reward, done, info, _)\n",
    "        reward_per_ep += reward\n",
    "        \n",
    "        next_state = agent.one_hot_state(next_state)\n",
    "        agent.remember(state, action, actions_available, reward, next_state, done)\n",
    "        agent.replay(episode)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            agent.target_train()\n",
    "            break\n",
    "    agent.save(weights_file_name)\n",
    "    end_time = time.time()\n",
    "    print(f\"{datetime.utcnow()} : Episode {str(episode)} total reward:{str(reward_per_ep)} avg reward: {str(reward_per_ep/500)} epsilon: {str(agent.get_epsilon())} time elapsed: {(end_time-total_start)/60:.2f}min\")\n",
    "total_end = time.time()\n",
    "print(f\"Total time: {total_end - total_start}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T03:02:04.576753Z",
     "start_time": "2024-03-25T03:01:35.880010Z"
    }
   },
   "id": "449ec4be417c2589",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9100ddb8eb4db8ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
